{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.load import MetaLoader, DialogueTrainLoader\n",
    "from utils.preprocess import Preprocessor, Augmentation\n",
    "from utils.encoder import Encoder\n",
    "\n",
    "from data import FH2024Dataset, collate_fn\n",
    "from net.tokenizer import SubWordEmbReaderUtil\n",
    "from net.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "swer_path = './sstm_v0p5_deploy/sstm_v4p49_np_n36134_d128.dat'\n",
    "swer = SubWordEmbReaderUtil(swer_path)\n",
    "\n",
    "meta_path = '../../datasets/FH_2024/subtask3/mdata.wst.txt.2023.08.23'\n",
    "meta_loader = MetaLoader(path=meta_path, swer=swer)\n",
    "img2id, id2img, img_similarity = meta_loader.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../../datasets/FH_2024/subtask3/task1.ddata.wst.txt\"\n",
    "train_diag_loader = DialogueTrainLoader(path=train_path)\n",
    "train_raw_dataset = train_diag_loader.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': ['안녕_하 세 요 코디 봇 입 니다 무엇 을 도와 드릴_까 요',\n",
       "  '최근 에 열린 꽃 축제 에 가_려고 하_는데 그때 입 을 스커트 를 포함_한 의상 추천_해 주 세 요',\n",
       "  '원하 시 는 스커트 기장 이 있 으신가 요',\n",
       "  '중간 기장 으로 보여_주 세 요',\n",
       "  '겉옷 이 포함_된 코디로 추천_해 드릴_까 요',\n",
       "  '얇 은 가디건 으로 추천 부탁 드려_요',\n",
       "  '네 반영 하_여 추천 드리 겠 습니다 잠시 만 기다려_주 세 요',\n",
       "  '아이보리 색상 의 머메이드 형 스커트 와 부드러운 소재 의 베이지 색상 가디건 을 포함_한 코디 를 추천_해 드립 니다 마음 에 드 시_나 요',\n",
       "  '상의 와 신발 은 캐쥬얼 한 디자인 이 마음 에 들_어 요 그런데 가디건 은 길이 가 조금 긴 것 같_아 짧 은 의상 으로 치마 는 활동_하 기 편한 스커트 로 부탁 드려_요',\n",
       "  '네 가디건 은 원하 시 는 색상 이 있_나 요',\n",
       "  '베이지색 계열 로 보여_주 세 요',\n",
       "  '네 반영 하_여 다시 추천 드리 겠 습니다 잠시 만 기다려_주 세 요',\n",
       "  '퍼프 소매 디자인 이 가미 된 베이지 색상 의 가디건 과 넛 넛 한 핏 으로 활동_하 기 편한 플레어 형 스커트 를 추천_해 드립 니다 마음 에 드 시_나 요',\n",
       "  '가디건 은 핏 이 마음 에 드_는데 스커트 는 때 가 탈 것 같_아 다른 색상 으로 보여_주 세 요',\n",
       "  '네 어두운 색상 으로 다시 추천_해 드리 겠 습니다 잠시 만 기다려_주 세 요',\n",
       "  '종아리 까지 오 는 블랙 색상 의 스커트 입 니다 마음 에 드 시_나 요',\n",
       "  '색상 이랑 디자인 이 튀 지_않 고 움직이 기 편해 보여 마음 에 들_어 요',\n",
       "  '마음 에 드 셨_다 니 다행 입 니다',\n",
       "  '선택_하 신 아이템 으로 구성_된 최종 코디 입니다 마음 에 드 시_나 요',\n",
       "  '네 스타일 에 신경_쓰 면서_도 간단_하 게 입_고 갈_수 있 을 것 같_아 마음 에 들_어 요',\n",
       "  '마음 에 드 셨_다 니 다행 입 니다',\n",
       "  '코디 봇 을 이용_해 주 셔 서 감사_합 니다'],\n",
       " 'coordi': [{0: 'CD-032', 1: 'BL-216', 2: 'SK-259', 3: 'SE-175'},\n",
       "  {0: 'CD-220', 1: 'BL-216', 2: 'SK-418', 3: 'SE-175'},\n",
       "  {0: 'CD-220', 1: 'BL-216', 2: 'SK-287', 3: 'SE-175'},\n",
       "  {0: 'CD-220', 1: 'BL-216', 2: 'SK-287', 3: 'SE-175'}],\n",
       " 'reward': ['USER_SUCCESS_PART',\n",
       "  'USER_SUCCESS_PART',\n",
       "  'USER_SUCCESS',\n",
       "  'USER_SUCCESS']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor(num_rank=3, num_coordi=4, top_k=50)\n",
    "train_dataset = preprocessor(train_raw_dataset, img2id, id2img, img_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "995"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = Augmentation(num_aug=5, num_rank=3, num_coordi=4, top_k=50)\n",
    "train_dataset = augmentation(train_dataset, img2id, id2img, img_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5970"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(swer=swer, img2id=img2id, num_coordi=4, mem_size=16, meta_size=4)\n",
    "encoded_train_dataset = encoder(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -- Training\n",
    "BATCH_SIZE = 16\n",
    "EPOCH = 10\n",
    "\n",
    "# -- Model\n",
    "KEY_SIZE = 300\n",
    "MEM_SIZE = 16\n",
    "HOPS = 3\n",
    "EVAL_NODE = '[6000,6000,6000,200][2000,2000]'\n",
    "DROP_PROB = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FH2024Dataset(dataset=encoded_train_dataset)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desc: torch.Size([16, 16, 128]), coordi: torch.Size([16, 3, 2048]), rank: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    desc = batch['description'].to(device)\n",
    "    coordi = batch['coordi'].to(device)\n",
    "    rank = batch['rank'].to(device)\n",
    "    break\n",
    "\n",
    "print(f\"desc: {desc.shape}, coordi: {coordi.shape}, rank: {rank.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_size = [len(img2id[i]) for i in range(4)] # 각 카테고리별 개수\n",
    "net = Model(emb_size=swer.get_emb_size(), \n",
    "            key_size=KEY_SIZE, \n",
    "            mem_size=MEM_SIZE,\n",
    "            meta_size=4, \n",
    "            hops=HOPS, \n",
    "            item_size=item_size, \n",
    "            coordi_size=4,\n",
    "            eval_node=EVAL_NODE, \n",
    "            num_rnk=3, \n",
    "            use_batch_norm=False, \n",
    "            use_dropout=True,\n",
    "            zero_prob=DROP_PROB,\n",
    "            use_multimodal=False,\n",
    "            img_feat_size=4096).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 6])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = net(desc, coordi)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7947, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "loss = criterion(logits, rank)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
